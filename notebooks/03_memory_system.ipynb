{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ironbox: Memory System\n",
    "\n",
    "This notebook demonstrates the Memory System in Ironbox, which allows the system to remember important information across sessions and provide context-aware responses.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Memory System in Ironbox consists of several components:\n",
    "\n",
    "1. **Memory Manager**: Central component that coordinates memory operations\n",
    "2. **Memory Indexer**: Processes and indexes new memories\n",
    "3. **Memory Retriever**: Retrieves relevant memories based on semantic similarity\n",
    "4. **Vector Store**: Manages vector embeddings for efficient semantic search\n",
    "5. **Database**: Persistent storage for memories and embeddings\n",
    "\n",
    "Let's explore how these components work together to provide a powerful memory system for Ironbox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules and initialize the Memory System."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Import Ironbox components\n",
    "from ironbox.core.memory import MemorySystem, Memory, VectorStore\n",
    "from ironbox.core.llm import LLMService\n",
    "from ironbox.db.operations import DatabaseOperations\n",
    "\n",
    "# Initialize the required services\n",
    "db_ops = DatabaseOperations()\n",
    "llm_service = LLMService()\n",
    "vector_store = VectorStore(db_ops)\n",
    "memory_system = MemorySystem(db_ops, llm_service, vector_store)\n",
    "\n",
    "print(\"Memory System initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Memories\n",
    "\n",
    "Let's start by storing some memories in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to store a memory\n",
    "def store_memory(content, user_id=\"demo-user\"):\n",
    "    print(f\"Storing memory: '{content}'\")\n",
    "    memory_id = memory_system.store_memory(content, user_id)\n",
    "    print(f\"Memory stored with ID: {memory_id}\\n\")\n",
    "    return memory_id\n",
    "\n",
    "# Store some memories about Kubernetes clusters\n",
    "memories = [\n",
    "    \"My production Kubernetes cluster is hosted on GKE and has 5 nodes.\",\n",
    "    \"The staging cluster is running Kubernetes version 1.25 and is hosted on AWS EKS.\",\n",
    "    \"My database credentials are stored in the 'db-credentials' secret in the 'database' namespace.\",\n",
    "    \"The frontend deployment in the production namespace has 3 replicas.\",\n",
    "    \"I need to upgrade the development cluster to Kubernetes 1.26 next week.\"\n",
    "]\n",
    "\n",
    "memory_ids = []\n",
    "for memory in memories:\n",
    "    memory_id = store_memory(memory)\n",
    "    memory_ids.append(memory_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Embedding Generation\n",
    "\n",
    "When a memory is stored, the system generates an embedding vector using the LLM service. Let's examine how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to demonstrate embedding generation\n",
    "def demonstrate_embedding_generation(content):\n",
    "    print(f\"Generating embedding for: '{content}'\")\n",
    "    embedding = llm_service.generate_embedding(content)\n",
    "    print(f\"Embedding shape: {embedding.shape}\")\n",
    "    print(f\"First 10 dimensions: {embedding[:10]}\\n\")\n",
    "    return embedding\n",
    "\n",
    "# Generate embeddings for a few example texts\n",
    "example_texts = [\n",
    "    \"Kubernetes cluster on GKE\",\n",
    "    \"Database credentials in secrets\",\n",
    "    \"Frontend deployment with replicas\"\n",
    "]\n",
    "\n",
    "for text in example_texts:\n",
    "    demonstrate_embedding_generation(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Memories\n",
    "\n",
    "Now let's retrieve memories based on semantic similarity to a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve memories\n",
    "def retrieve_memories(query, user_id=\"demo-user\", limit=3):\n",
    "    print(f\"Retrieving memories for query: '{query}'\")\n",
    "    memories = memory_system.retrieve_memories(query, user_id, limit=limit)\n",
    "    print(f\"Retrieved {len(memories)} memories:\")\n",
    "    for i, memory in enumerate(memories):\n",
    "        print(f\"  {i+1}. '{memory.content}' (Similarity: {memory.similarity:.4f})\")\n",
    "    print()\n",
    "    return memories\n",
    "\n",
    "# Retrieve memories for different queries\n",
    "queries = [\n",
    "    \"Where is my production cluster hosted?\",\n",
    "    \"What are my database credentials?\",\n",
    "    \"How many replicas does the frontend have?\",\n",
    "    \"What Kubernetes version is my staging cluster running?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    retrieve_memories(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Importance and Recency\n",
    "\n",
    "The Memory System considers both importance and recency when retrieving memories. Let's explore how these factors affect memory retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update memory importance\n",
    "def update_memory_importance(memory_id, importance):\n",
    "    print(f\"Updating importance of memory {memory_id} to {importance}\")\n",
    "    memory_system.update_memory_importance(memory_id, importance)\n",
    "    print(\"Importance updated successfully.\\n\")\n",
    "\n",
    "# Update importance of some memories\n",
    "update_memory_importance(memory_ids[0], 0.9)  # Production cluster is very important\n",
    "update_memory_importance(memory_ids[2], 0.8)  # Database credentials are important\n",
    "\n",
    "# Function to simulate memory access (updates last_accessed timestamp)\n",
    "def access_memory(memory_id):\n",
    "    print(f\"Accessing memory {memory_id}\")\n",
    "    memory_system.access_memory(memory_id)\n",
    "    print(\"Memory accessed successfully.\\n\")\n",
    "\n",
    "# Access some memories to update their recency\n",
    "access_memory(memory_ids[1])  # Staging cluster\n",
    "access_memory(memory_ids[3])  # Frontend deployment\n",
    "\n",
    "# Retrieve memories with importance and recency factors\n",
    "print(\"Retrieving memories with importance and recency factors:\")\n",
    "query = \"Tell me about my Kubernetes clusters\"\n",
    "memories = memory_system.retrieve_memories(query, \"demo-user\", limit=5, importance_weight=0.3, recency_weight=0.2)\n",
    "print(f\"Retrieved {len(memories)} memories:\")\n",
    "for i, memory in enumerate(memories):\n",
    "    print(f\"  {i+1}. '{memory.content}'\")\n",
    "    print(f\"     Similarity: {memory.similarity:.4f}, Importance: {memory.importance:.4f}, Last Accessed: {memory.last_accessed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Context in Query Processing\n",
    "\n",
    "Let's see how the Memory System provides context for query processing in the Agent Core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Agent Core\n",
    "from ironbox.core.agent_core import AgentCore\n",
    "\n",
    "# Initialize Agent Core with Memory System\n",
    "agent_core = AgentCore(memory_system=memory_system)\n",
    "\n",
    "# Function to process a query with memory context\n",
    "def process_query_with_memory(query, user_id=\"demo-user\", session_id=\"demo-session\"):\n",
    "    print(f\"Processing query with memory context: '{query}'\")\n",
    "    \n",
    "    # Retrieve relevant memories\n",
    "    memories = memory_system.retrieve_memories(query, user_id, limit=3)\n",
    "    memory_context = \"\\n\".join([f\"- {memory.content}\" for memory in memories])\n",
    "    print(f\"Memory context:\\n{memory_context}\\n\")\n",
    "    \n",
    "    # Process the query with memory context\n",
    "    response = agent_core.process_query(query, session_id=session_id, user_id=user_id)\n",
    "    print(f\"Response: {response['response']}\\n\")\n",
    "    return response\n",
    "\n",
    "# Process queries with memory context\n",
    "memory_queries = [\n",
    "    \"What cloud provider hosts my production cluster?\",\n",
    "    \"Where are my database credentials stored?\",\n",
    "    \"Do I need to upgrade any of my clusters soon?\"\n",
    "]\n",
    "\n",
    "for query in memory_queries:\n",
    "    process_query_with_memory(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Summarization\n",
    "\n",
    "The Memory System can summarize memories to provide a concise overview of what it knows about a topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to summarize memories\n",
    "def summarize_memories(topic, user_id=\"demo-user\"):\n",
    "    print(f\"Summarizing memories about: '{topic}'\")\n",
    "    \n",
    "    # Retrieve relevant memories\n",
    "    memories = memory_system.retrieve_memories(topic, user_id, limit=10)\n",
    "    memory_texts = [memory.content for memory in memories]\n",
    "    \n",
    "    # Generate a summary using the LLM service\n",
    "    prompt = f\"Summarize the following information about {topic}:\\n\\n\" + \"\\n\".join([f\"- {text}\" for text in memory_texts])\n",
    "    summary = llm_service.generate_text(prompt)\n",
    "    \n",
    "    print(f\"Summary: {summary}\\n\")\n",
    "    return summary\n",
    "\n",
    "# Summarize memories about different topics\n",
    "topics = [\"Kubernetes clusters\", \"database information\", \"deployment configuration\"]\n",
    "\n",
    "for topic in topics:\n",
    "    summarize_memories(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Persistence\n",
    "\n",
    "Let's examine how memories are stored in the database for persistence across sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to demonstrate memory persistence\n",
    "def demonstrate_memory_persistence():\n",
    "    print(\"=== Memory Persistence Demo ===\")\n",
    "    \n",
    "    # Store a new memory\n",
    "    content = \"The API server for my production cluster is exposed on port 6443\"\n",
    "    user_id = \"demo-user\"\n",
    "    memory_id = memory_system.store_memory(content, user_id)\n",
    "    print(f\"Stored new memory with ID: {memory_id}\")\n",
    "    \n",
    "    # Retrieve the memory from the database\n",
    "    memory = db_ops.get_memory(memory_id)\n",
    "    print(f\"Retrieved from database: '{memory.content}'\")\n",
    "    print(f\"User ID: {memory.user_id}\")\n",
    "    print(f\"Created at: {memory.created_at}\")\n",
    "    print(f\"Last accessed: {memory.last_accessed}\")\n",
    "    print(f\"Importance: {memory.importance}\")\n",
    "    \n",
    "    # Get the embedding\n",
    "    embedding = db_ops.get_embedding(memory_id)\n",
    "    print(f\"Embedding dimensions: {len(embedding)}\")\n",
    "    print(f\"First 5 dimensions: {embedding[:5]}\")\n",
    "    \n",
    "    # Simulate a system restart\n",
    "    print(\"\\nSimulating system restart...\")\n",
    "    new_memory_system = MemorySystem(db_ops, llm_service, vector_store)\n",
    "    \n",
    "    # Retrieve the memory after restart\n",
    "    query = \"What port is my API server on?\"\n",
    "    memories = new_memory_system.retrieve_memories(query, user_id, limit=1)\n",
    "    print(f\"Retrieved after restart: '{memories[0].content}'\")\n",
    "\n",
    "# Run the demonstration\n",
    "demonstrate_memory_persistence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've explored the Memory System in Ironbox:\n",
    "\n",
    "1. **Memory Storage**: Storing memories with content, user ID, and metadata\n",
    "2. **Embedding Generation**: Creating vector embeddings for semantic search\n",
    "3. **Memory Retrieval**: Finding relevant memories based on semantic similarity\n",
    "4. **Importance and Recency**: Considering both factors in memory retrieval\n",
    "5. **Memory Context**: Using memories to provide context for query processing\n",
    "6. **Memory Summarization**: Generating concise summaries of related memories\n",
    "7. **Memory Persistence**: Storing memories in the database for persistence across sessions\n",
    "\n",
    "The Memory System is a critical component of Ironbox that allows it to maintain context across sessions and provide more personalized and relevant responses to user queries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
